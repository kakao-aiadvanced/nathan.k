import bs4
from langchain import hub
from langchain_chroma import Chroma
from langchain_core.output_parsers import JsonOutputParser
from langchain_core.prompts import PromptTemplate
from langchain_community.document_loaders import WebBaseLoader
from langchain_openai import ChatOpenAI
from langchain_openai import OpenAIEmbeddings
from langchain_text_splitters import RecursiveCharacterTextSplitter
import os

# conf
query = "Describe about agent memory."
api_key = "DELETED"
max_attempts_for_remove_hallucination = 3
docs_urls = [
    "https://lilianweng.github.io/posts/2023-06-23-agent/",
    "https://lilianweng.github.io/posts/2023-03-15-prompt-engineering/",
    "https://lilianweng.github.io/posts/2023-10-25-adv-attack-llm/",
]

os.environ["OPENAI_API_KEY"] = api_key
llm = ChatOpenAI(model="gpt-4o-mini")

# Function to load documents from URLs
def load_documents(urls):
    all_docs = []
    for url in urls:
        loader = WebBaseLoader(
            web_paths=(url,),
            bs_kwargs=dict(
                parse_only=bs4.SoupStrainer(
                    class_=("post-content", "post-title", "post-header")
                )
            ),
        )
        docs = loader.load()
        all_docs.extend(docs)
    
    return all_docs

# Function to split documents
def split_documents(docs, chunk_size=1000, chunk_overlap=200):
    text_splitter = RecursiveCharacterTextSplitter(chunk_size=chunk_size, chunk_overlap=chunk_overlap)
    splits = text_splitter.split_documents(docs)
    return splits

# Load documents from URLs
documents = load_documents(docs_urls)

# Split the loaded documents
splits = split_documents(documents)

# Initialize the embedding model
embedding_model = OpenAIEmbeddings(model='text-embedding-3-small')

# Embed the document chunks and store them in a vector store
vector_store = Chroma.from_documents(splits, embedding_model)

retriever = vector_store.as_retriever(search_type = "similarity", search_kwargs={'k': 6})

# Retrieve similar documents based on the query
similar_docs = retriever.get_relevant_documents(query)

all_chunks = ""

for i, doc in enumerate(similar_docs):
    all_chunks += doc.page_content + "\n\n"

parser = JsonOutputParser()

# Create the prompt template
relevance_check_prompt = PromptTemplate(
    template=(
        "You are an expert at determining the relevance between two pieces of text. "
        "Evaluate the relevance between the user query and the retrieved document chunk, "
        "and respond in the form of either {{\"relevance\": \"yes\"}} or {{\"relevance\": \"no\"}}. "
        "Choose \"yes\" if the texts are closely related, otherwise choose \"no\".\n"
        "{format_instructions}\n"
        "User query: {query}\n"
        "Retrieved chunk: {document_chunk}\n"
    ),
    input_variables=["query", "document_chunk"],
    partial_variables={"format_instructions": parser.get_format_instructions()}
)

relevance_check_chain = relevance_check_prompt | llm | parser

relevance_result = relevance_check_chain.invoke({'query': query, 'document_chunk': all_chunks})['relevance']

if relevance_result == "no":
    print("관련된 문서를 찾지 못했습니다")
    exit()

print("relevance_check_result : " + relevance_result)

main_prompt = hub.pull("rlm/rag-prompt")
main_chain = main_prompt | llm

hallucination_check_prompt = PromptTemplate(
    template=(
        "You are an expert at identifying hallucinations in text generated by AI. "
        "Evaluate whether the content of the generated message includes information not supported by the retrieved document chunk. "
        "Respond in the form of either {{\"hallucination\": \"yes\"}} if hallucinations are present, or {{\"hallucination\": \"no\"}} if the message is fully supported by the chunk.\n"
        "{format_instructions}\n"
        "Retrieved Chunk: {retrieved_chunk}\n"
        "Generated Message: {generated_message}\n"
    ),
    input_variables=["retrieved_chunk", "generated_message"],
    partial_variables={"format_instructions": JsonOutputParser().get_format_instructions()}
)
hallucination_check_chain = hallucination_check_prompt | llm | parser

def check_for_hallucinations(retrieved_chunk, generated_message):
    result = hallucination_check_chain.invoke({
        'retrieved_chunk': retrieved_chunk,
        'generated_message': generated_message
    })
    
    # Assuming the result is a dictionary or JSON-like object
    # that contains a key `hallucination` with either "yes" or "no"
    hallucination_present = result.get("hallucination", "no") == "yes"

attempt = 0
hallucination_present = True
generated_message = None

while attempt < max_attempts_for_remove_hallucination and hallucination_present:
    # Generate a message using the main_chain
    generated_message = main_chain.invoke({
        'context': all_chunks,
        'question': query
    }).content
    
    # Check for hallucinations
    hallucination_present = check_for_hallucinations(all_chunks, generated_message)
    attempt += 1

print(generated_message)
